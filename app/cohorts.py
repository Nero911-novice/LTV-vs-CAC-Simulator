import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import random
from typing import Dict, List, Tuple, Optional
def rider_cohort_analysis():
    """–ö–æ–≥–æ—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–æ–¥–∏—Ç–µ–ª–µ–π"""
    st.header("üìà –ö–æ–≥–æ—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–æ–¥–∏—Ç–µ–ª–µ–π")
    
    st.markdown("""
    **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ ride-hailing**: –ø–µ—Ä–≤–∞—è –ø–æ–µ–∑–¥–∫–∞ ‚â† –∞–∫—Ç–∏–≤–∞—Ü–∏—è. –ö–ª—é—á–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ - 
    time to second ride –∏ —á–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–≤—ã–µ 30 –¥–Ω–µ–π.
    """)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–≥–æ—Ä—Ç")
        
        num_cohorts = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—è—á–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç", 6, 18, 12)
        base_cohort_size = st.slider("–†–∞–∑–º–µ—Ä –±–∞–∑–æ–≤–æ–π –∫–æ–≥–æ—Ä—Ç—ã", 1000, 10000, 3000)
        seasonal_effect = st.checkbox("–£—á–µ—Å—Ç—å —Å–µ–∑–æ–Ω–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã", True)
        
    with col2:
        st.subheader("üéØ –ú–µ—Ç—Ä–∏–∫–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏")
        
        time_to_second_ride = st.slider("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–æ 2-–π –ø–æ–µ–∑–¥–∫–∏ (–¥–Ω–∏)", 3, 21, 7)
        first_month_frequency = st.slider("–ü–æ–µ–∑–¥–æ–∫ –≤ –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü (–∞–∫—Ç–∏–≤–Ω—ã–µ)", 2, 8, 4)
        activation_rate = st.slider("–î–æ–ª—è –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (%)", 30, 80, 55)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–≥–æ—Ä—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    cohort_data = generate_rider_cohort_data(
        num_cohorts, base_cohort_size, seasonal_effect, 
        time_to_second_ride, first_month_frequency, activation_rate
    )
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–≥–æ—Ä—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    create_rider_cohort_table(cohort_data)
    
    # –ê–Ω–∞–ª–∏–∑ retention –∫—Ä–∏–≤—ã—Ö
    create_retention_curves(cohort_data)
    
    # –ê–Ω–∞–ª–∏–∑ revenue cohorts
    create_revenue_cohort_analysis(cohort_data)

def generate_rider_cohort_data(num_cohorts: int, base_size: int, seasonal: bool,
                              time_to_second: int, first_frequency: int, activation_rate: int) -> List[Dict]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª–µ–π"""
    
    cohorts = []
    
    for i in range(num_cohorts):
        month = i + 1
        
        # –°–µ–∑–æ–Ω–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –¥–ª—è ride-hailing
        seasonal_multiplier = 1.0
        if seasonal:
            # –ó–∏–º–∞ (–¥–µ–∫-—Ñ–µ–≤) - –±–æ–ª—å—à–µ –ø–æ–µ–∑–¥–æ–∫ –∏–∑-–∑–∞ –ø–æ–≥–æ–¥—ã
            if month in [12, 1, 2]:
                seasonal_multiplier = 1.4
            # –õ–µ—Ç–æ (–∏—é–Ω-–∞–≤–≥) - –º–µ–Ω—å—à–µ –ø–æ–µ–∑–¥–æ–∫, –±–æ–ª—å—à–µ –ø–µ—à–∫–æ–º/–≤–µ–ª–æ—Å–∏–ø–µ–¥
            elif month in [6, 7, 8]:
                seasonal_multiplier = 0.8
            # –î–æ–∂–¥–ª–∏–≤—ã–µ –º–µ—Å—è—Ü—ã (–æ–∫—Ç-–Ω–æ—è, –º–∞—Ä-–∞–ø—Ä)
            elif month in [10, 11, 3, 4]:
                seasonal_multiplier = 1.2
        
        cohort_size = int(base_size * seasonal_multiplier * np.random.uniform(0.9, 1.1))
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–æ–≥–æ—Ä—Ç—ã
        activated_users = int(cohort_size * (activation_rate / 100))
        
        # Retention pattern –¥–ª—è ride-hailing (–±–æ–ª–µ–µ –∫—Ä—É—Ç–æ–µ –ø–∞–¥–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ)
        monthly_retention = []
        for month_num in range(1, 13):
            if month_num == 1:
                retention = 1.0  # 100% –≤ –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü
            elif month_num == 2:
                retention = activation_rate / 100  # –ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–æ –≤—Ç–æ—Ä–æ–π –º–µ—Å—è—Ü
            else:
                # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —Å –≤—ã—Ö–æ–¥–æ–º –Ω–∞ –ø–ª–∞—Ç–æ
                base_retention = 0.25 + (activation_rate / 100 - 0.25) * np.exp(-(month_num - 2) / 4)
                retention = max(base_retention, 0.15)  # –ú–∏–Ω–∏–º—É–º 15% –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π retention
            
            monthly_retention.append(retention)
        
        # –†–∞—Å—á–µ—Ç –ø–æ–º–µ—Å—è—á–Ω–æ–π –≤—ã—Ä—É—á–∫–∏
        aov = 350 * seasonal_multiplier  # AOV –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–µ–∑–æ–Ω–∞
        take_rate = 0.25
        
        monthly_revenue = []
        for month_num, retention in enumerate(monthly_retention):
            active_users = cohort_size * retention
            
            # –ß–∞—Å—Ç–æ—Ç–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å—Ç–∞–¥–∏–∏ –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            if month_num == 0:
                frequency = first_frequency * 0.6  # –ü–µ—Ä–≤—ã–π –º–µ—Å—è—Ü - —á–∞—Å—Ç–∏—á–Ω—ã–π
            elif month_num <= 2:
                frequency = first_frequency  # –ù–∞—á–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            else:
                # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–æ—Ç—ã –¥–ª—è retained users
                frequency = first_frequency * 1.2
            
            revenue = active_users * aov * take_rate * frequency
            monthly_revenue.append(revenue)
        
        # –†–∞—Å—á–µ—Ç LTV –∫–æ–≥–æ—Ä—Ç—ã
        total_revenue = sum(monthly_revenue)
        ltv_per_user = total_revenue / cohort_size
        
        cohorts.append({
            'month': month,
            'cohort_size': cohort_size,
            'activated_users': activated_users,
            'activation_rate': activation_rate / 100,
            'monthly_retention': monthly_retention,
            'monthly_revenue': monthly_revenue,
            'ltv_per_user': ltv_per_user,
            'seasonal_factor': seasonal_multiplier,
            'time_to_second_ride': time_to_second + np.random.normal(0, 2)
        })
    
    return cohorts

def create_rider_cohort_table(cohort_data: List[Dict]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–≥–æ—Ä—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã retention"""
    st.subheader("üìä –ö–æ–≥–æ—Ä—Ç–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ retention (–≤ %)")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è heatmap
    cohort_months = len(cohort_data)
    max_periods = 12
    
    retention_matrix = np.zeros((cohort_months, max_periods))
    
    for i, cohort in enumerate(cohort_data):
        for j in range(min(len(cohort['monthly_retention']), max_periods)):
            retention_matrix[i, j] = cohort['monthly_retention'][j] * 100
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π heatmap
    fig = go.Figure(data=go.Heatmap(
        z=retention_matrix,
        x=[f"M{i+1}" for i in range(max_periods)],
        y=[f"–ö–æ–≥–æ—Ä—Ç–∞ {i+1}" for i in range(cohort_months)],
        colorscale='RdYlGn',
        zmin=0,
        zmax=100,
        text=[[f"{val:.1f}%" for val in row] for row in retention_matrix],
        texttemplate="%{text}",
        textfont={"size":10},
        colorbar=dict(title="Retention %")
    ))
    
    fig.update_layout(
        title="Retention Rate –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º (—á–µ–º –∑–µ–ª–µ–Ω–µ–µ, —Ç–µ–º –ª—É—á—à–µ)",
        xaxis_title="–ú–µ—Å—è—Ü —Å –º–æ–º–µ–Ω—Ç–∞ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è",
        yaxis_title="–ö–æ–≥–æ—Ä—Ç–∞",
        height=500
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    st.subheader("üìà –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ retention")
    
    avg_retention = np.mean(retention_matrix, axis=0)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("1-–π –º–µ—Å—è—Ü", f"{avg_retention[0]:.1f}%")
    with col2:
        st.metric("2-–π –º–µ—Å—è—Ü (–∞–∫—Ç–∏–≤–∞—Ü–∏—è)", f"{avg_retention[1]:.1f}%")
    with col3:
        st.metric("6-–π –º–µ—Å—è—Ü", f"{avg_retention[5]:.1f}%")
    with col4:
        st.metric("12-–π –º–µ—Å—è—Ü", f"{avg_retention[11]:.1f}%")

def create_retention_curves(cohort_data: List[Dict]):
    """–ö—Ä–∏–≤—ã–µ retention –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç"""
    st.subheader("üìâ –ö—Ä–∏–≤—ã–µ retention –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º")
    
    fig = go.Figure()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç
    selected_cohorts = [0, len(cohort_data)//4, len(cohort_data)//2, len(cohort_data)-1]
    colors = ['blue', 'green', 'orange', 'red']
    
    for i, cohort_idx in enumerate(selected_cohorts):
        if cohort_idx < len(cohort_data):
            cohort = cohort_data[cohort_idx]
            months = list(range(1, len(cohort['monthly_retention']) + 1))
            retention_pct = [r * 100 for r in cohort['monthly_retention']]
            
            fig.add_trace(go.Scatter(
                x=months,
                y=retention_pct,
                mode='lines+markers',
                name=f"–ö–æ–≥–æ—Ä—Ç–∞ {cohort['month']} (—Å–µ–∑–æ–Ω {cohort['seasonal_factor']:.1f}x)",
                line=dict(color=colors[i], width=3),
                marker=dict(size=6)
            ))
    
    # –°—Ä–µ–¥–Ω—è—è –∫—Ä–∏–≤–∞—è
    avg_retention = []
    for month_idx in range(12):
        month_retentions = [c['monthly_retention'][month_idx] * 100 
                          for c in cohort_data if month_idx < len(c['monthly_retention'])]
        avg_retention.append(np.mean(month_retentions))
    
    fig.add_trace(go.Scatter(
        x=list(range(1, 13)),
        y=avg_retention,
        mode='lines+markers',
        name="–°—Ä–µ–¥–Ω—è—è retention",
        line=dict(color='black', width=4, dash='dash'),
        marker=dict(size=8)
    ))
    
    fig.update_layout(
        title="Retention curves: –≤–ª–∏—è–Ω–∏–µ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –ª–æ—è–ª—å–Ω–æ—Å—Ç—å",
        xaxis_title="–ú–µ—Å—è—Ü —Å –º–æ–º–µ–Ω—Ç–∞ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è",
        yaxis_title="Retention (%)",
        height=500
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # –ò–Ω—Å–∞–π—Ç—ã
    st.info("""
    üí° **–ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã ride-hailing retention**:
    
    1. **–ö—Ä—É—Ç–æ–µ –ø–∞–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ 1-–≥–æ –º–µ—Å—è—Ü–∞** - –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å –±—ã—Å—Ç—Ä–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
    2. **–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –Ω–∞ 3-4 –º–µ—Å—è—Ü–µ** - —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–≤—ã—á–∫–∏
    3. **–°–µ–∑–æ–Ω–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è** - –∑–∏–º–Ω–∏–µ –∫–æ–≥–æ—Ä—Ç—ã —á–∞—Å—Ç–æ –∏–º–µ—é—Ç –ª—É—á—à–∏–π retention
    4. **–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –ø–ª–∞—Ç–æ 15-25%** - –±–∞–∑–∞ –ª–æ—è–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    """)

def create_revenue_cohort_analysis(cohort_data: List[Dict]):
    """–ê–Ω–∞–ª–∏–∑ –≤—ã—Ä—É—á–∫–∏ –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º"""
    st.subheader("üí∞ Revenue Cohort Analysis")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    cohort_months = len(cohort_data)
    max_periods = 12
    
    revenue_matrix = np.zeros((cohort_months, max_periods))
    
    for i, cohort in enumerate(cohort_data):
        for j in range(min(len(cohort['monthly_revenue']), max_periods)):
            revenue_matrix[i, j] = cohort['monthly_revenue'][j] / 1000  # –í —Ç—ã—Å—è—á–∞—Ö —Ä—É–±–ª–µ–π
    
    # Cumulative revenue
    cumulative_revenue = np.cumsum(revenue_matrix, axis=1)
    
    # –ì—Ä–∞—Ñ–∏–∫ cumulative revenue
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('–ú–µ—Å—è—á–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º', '–ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è –≤—ã—Ä—É—á–∫–∞')
    )
    
    # Monthly revenue heatmap
    fig.add_trace(
        go.Heatmap(
            z=revenue_matrix,
            x=[f"M{i+1}" for i in range(max_periods)],
            y=[f"–ö–æ–≥–æ—Ä—Ç–∞ {i+1}" for i in range(cohort_months)],
            colorscale='Blues',
            name="Monthly Revenue",
            showscale=False
        ),
        row=1, col=1
    )
    
    # Cumulative revenue heatmap
    fig.add_trace(
        go.Heatmap(
            z=cumulative_revenue,
            x=[f"M{i+1}" for i in range(max_periods)],
            y=[f"–ö–æ–≥–æ—Ä—Ç–∞ {i+1}" for i in range(cohort_months)],
            colorscale='Greens',
            name="Cumulative Revenue",
            colorbar=dict(title="–í—ã—Ä—É—á–∫–∞ (—Ç—ã—Å. —Ä—É–±)")
        ),
        row=1, col=2
    )
    
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)
    
    # LTV –∞–Ω–∞–ª–∏–∑
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä LTV –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º")
        ltv_data = pd.DataFrame([
            {
                '–ö–æ–≥–æ—Ä—Ç–∞': f"–ö–æ–≥–æ—Ä—Ç–∞ {c['month']}",
                '–†–∞–∑–º–µ—Ä': c['cohort_size'],
                'LTV –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è': f"{c['ltv_per_user']:,.0f} —Ä—É–±",
                '–°–µ–∑–æ–Ω–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä': f"{c['seasonal_factor']:.1f}x",
                '–ê–∫—Ç–∏–≤–∞—Ü–∏—è': f"{c['activation_rate']:.1%}"
            }
            for c in cohort_data
        ])
        st.dataframe(ltv_data, use_container_width=True)
    
    with col2:
        st.markdown("#### üí° –í—ã–≤–æ–¥—ã")
        
        avg_ltv = np.mean([c['ltv_per_user'] for c in cohort_data])
        max_ltv_cohort = max(cohort_data, key=lambda x: x['ltv_per_user'])
        min_ltv_cohort = min(cohort_data, key=lambda x: x['ltv_per_user'])
        
        st.metric("–°—Ä–µ–¥–Ω–∏–π LTV", f"{avg_ltv:,.0f} —Ä—É–±")
        st.success(f"–õ—É—á—à–∞—è –∫–æ–≥–æ—Ä—Ç–∞: {max_ltv_cohort['month']} ({max_ltv_cohort['ltv_per_user']:,.0f} —Ä—É–±)")
        st.warning(f"–•—É–¥—à–∞—è –∫–æ–≥–æ—Ä—Ç–∞: {min_ltv_cohort['month']} ({min_ltv_cohort['ltv_per_user']:,.0f} —Ä—É–±)")
        
        ltv_variance = (max_ltv_cohort['ltv_per_user'] - min_ltv_cohort['ltv_per_user']) / avg_ltv
        st.info(f"–†–∞–∑–±—Ä–æ—Å LTV: {ltv_variance:.1%}")
